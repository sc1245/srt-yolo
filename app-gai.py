import warnings
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')
import streamlit as st
from streamlit_option_menu import option_menu
import cv2
import os
import requests
from PIL import Image
from io import BytesIO
import numpy as np
from ultralytics import YOLO
from urllib.parse import urlparse
import tempfile
import urllib.request
from collections import defaultdict
import time
from datetime import datetime
import shutil

if not os.path.exists('history'):
    os.makedirs('history')

# åœ¨è¿™å¯åŠ å…¥åˆ«çš„æƒé‡æ–‡ä»¶
model_map = {
    'FPCDet': 'runs/detect/train4/weights/best.pt',
    #'yolov8': 'runs/detect/train/weights/best.pt'
}

st.set_page_config(page_title="åœ¨çº¿æ£€æµ‹å¹³å°", page_icon=":desktop_computer:")

st.markdown("<h1 style='text-align: center'>åœ¨çº¿æ£€æµ‹å¹³å°</h1>", unsafe_allow_html=True)
with st.sidebar:
    model_select = st.selectbox("æ£€æµ‹æ¨¡å‹é€‰æ‹©", list(model_map.keys()))
    if model_select not in st.session_state:
        st.session_state[model_select] = YOLO(model_map[model_select])
    selected = option_menu("åŠŸèƒ½åˆ—è¡¨", ["é¦–é¡µ", "å›¾ç‰‡æ£€æµ‹", "è§†é¢‘æ£€æµ‹", "æ‘„åƒå¤´æ£€æµ‹", "å†å²æ£€æµ‹", "è®¡æ•°å¯è§†åŒ–"],
                           icons=['house-gear', 'image', 'film', 'webcam', 'hourglass-split', 'graph-up'],
                           menu_icon="list-stars", default_index=0)


def predict_image():
    results = st.session_state[model_select].predict(source='predict_img.jpg', **{'save': False, 'show_conf': True},
                                                     stream=True)
    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
    for result in results:
        label_dic = result.names
        frame = result.orig_img
        for a, b, c in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.cls.cpu().numpy(), result.boxes.conf):
            # è·å–è¾¹ç•Œæ¡†åæ ‡å’Œæ ‡ç­¾
            x1, y1, x2, y2 = map(int, a)  # è¾¹ç•Œæ¡†åæ ‡
            label = label_dic[b]
            confidence = c

            # åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 5)
            text = f"{label} ({confidence:.2f})"
            font_scale = 1
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_thickness = 2

            text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]
            text_x, text_y = x1, y1 - 10
            text_bg_x1, text_bg_y1 = text_x, text_y - text_size[1]
            text_bg_x2, text_bg_y2 = text_x + text_size[0], text_y

            cv2.rectangle(frame, (text_bg_x1, text_bg_y1), (text_bg_x2, text_bg_y2), (0, 0, 255), -1)
            cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), font_thickness,
                        lineType=cv2.LINE_AA)
        # è½¬æ¢ä¸ºRGBæ ¼å¼
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    return frame_rgb, result.boxes.xyxy.cpu().numpy().shape[0]


def predict_video(video_path):
    if 'video_path' in locals():
        with st.spinner("æ£€æµ‹ä¸­ï¼Œè¯·ç¨ç­‰..."):
            cap = cv2.VideoCapture(video_path)
            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)

            # è®¾ç½®è¾“å‡ºè§†é¢‘æ–‡ä»¶
            output_path = "predict_video.mp4"
            fourcc = cv2.VideoWriter_fourcc(*'X264')
            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

            frame_rate_divider = 1  # æ¯1å¸§è¿›è¡Œä¸€æ¬¡æ£€æµ‹
            frame_count = 0
            counts = defaultdict(int)
            object_str = ""
            index = 0
            detection_times = []  # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„æ£€æµ‹æ—¶é—´æ•°æ®
            detection_counts = []  # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„æ£€æµ‹ä¸ªæ•°æ•°æ®

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # æ¯éš” frame_rate_divider å¸§æ£€æµ‹ä¸€æ¬¡
                if frame_count % frame_rate_divider == 0:
                    results = st.session_state[model_select].predict(source=frame,
                                                                     **{'save': False, 'show_conf': False}, stream=True)

                    key = f"({index}): "
                    index += 1
                    for result in results:
                        label_dic = result.names
                        for a, b, c in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.cls.cpu().numpy(),
                                           result.boxes.conf):
                            # è·å–è¾¹ç•Œæ¡†åæ ‡å’Œæ ‡ç­¾
                            x1, y1, x2, y2 = map(int, a)  # è¾¹ç•Œæ¡†åæ ‡
                            label = label_dic[b]
                            confidence = c

                            # åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 5)
                            text = f"{label} ({confidence:.2f})"
                            font_scale = 1
                            font = cv2.FONT_HERSHEY_SIMPLEX
                            font_thickness = 2

                            text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]
                            text_x, text_y = x1, y1 - 10
                            text_bg_x1, text_bg_y1 = text_x, text_y - text_size[1]
                            text_bg_x2, text_bg_y2 = text_x + text_size[0], text_y

                            cv2.rectangle(frame, (text_bg_x1, text_bg_y1), (text_bg_x2, text_bg_y2), (0, 0, 255), -1)
                            cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255),
                                        font_thickness, lineType=cv2.LINE_AA)
                    counts = defaultdict(int)  # é‡ç½®è®¡æ•°
                    current_time = time.time()
                    detection_times.append(current_time)  # current_timeä¸ºå½“å‰æ—¶é—´
                    detection_counts.append(result.boxes.xyxy.cpu().numpy().shape[0])  # count_numä¸ºå½“å‰æ£€æµ‹ä¸ªæ•°

                # å†™å…¥è¾“å‡ºè§†é¢‘
                out.write(frame)
                frame_count += 1

            # å…³é—­æ–‡ä»¶
            cap.release()
            out.release()
            video_file = open(output_path, "rb")
            video_bytes = video_file.read()
            # st.video(video_bytes)
    else:
        st.error("è§†é¢‘æ£€æµ‹å¤±è´¥", icon='ğŸš¨')


if selected == 'é¦–é¡µ':
    st.subheader("æœ¬å¹³å°æ˜¯åŸºäºyoloç®—æ³•å¯¹å›¾ç‰‡ã€è§†é¢‘å’Œæ‘„åƒå¤´ä¸‰ç§è¾“å…¥å®ç°å¯¹æŸ‘æ©˜è¿›è¡Œæ£€æµ‹ï¼Œå›¾ç‰‡ä¸è§†é¢‘æ£€æµ‹åŠŸèƒ½æ”¯æŒæ–‡ä»¶ä¸Šä¼ æˆ–URLè¾“å…¥å½¢å¼è¿›è¡Œæ£€æµ‹ï¼Œæ¯æ¬¡æ£€æµ‹çš„ç»“æœéƒ½å¯åœ¨å†å²æ£€æµ‹ä¸­æŸ¥çœ‹")

elif selected == 'å›¾ç‰‡æ£€æµ‹':
    options = [":material/image:è¯»å–å›¾ç‰‡", ":material/link:è¯»å–URL"]
    selection = st.pills("è¯·é€‰æ‹©è¯»å–æ–¹å¼", options, default=":material/image:è¯»å–å›¾ç‰‡")
    if selection == options[0]:
        uploaded_file = st.file_uploader("è¯·ä¸Šä¼ éœ€æ£€æµ‹çš„å›¾åƒ", type=["jpg", "jpeg", "png"])
        start_btn = st.button("æ£€æµ‹")
        col1, col2 = st.columns([5, 5])
        if start_btn:
            if uploaded_file is not None:
                with open('predict_img.jpg', "wb") as f:
                    f.write(uploaded_file.getbuffer())
                f.close()
                frame_rgb, count_num = predict_image()
                timestamp = int(time.time())
                cv2.imwrite("history/{}_image.jpg".format(timestamp), cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR))
                with open("history.txt", mode='a+', encoding='utf8') as f:
                    f.write("{}\t{}\n".format('history/{}_image.jpg'.format(timestamp),
                                              datetime.now().strftime('%Y-%m-%d')))
                f.close()
                with col1:
                    st.markdown("<h4 style='text-align: center'>åŸå§‹å›¾åƒ</h4>", unsafe_allow_html=True)
                    st.image('predict_img.jpg')
                with col2:
                    st.markdown("<h4 style='text-align: center'>ç»“æœå›¾åƒ</h4>", unsafe_allow_html=True)
                    st.image(frame_rgb, channels="RGB")
                    st.markdown("<h4 style='text-align: center'>æ£€æµ‹ä¸ªæ•°: {}</h4>".format(count_num),
                                unsafe_allow_html=True)
                img_pil = Image.fromarray(frame_rgb)
                buf = BytesIO()
                img_pil.save(buf, format="JPEG")
                byte_im = buf.getvalue()

                st.download_button(
                    label="Download result",
                    data=byte_im,
                    file_name="{}_image_file_predict.jpg".format(int(time.time())),
                    mime="image/jpg"
                )
            else:
                st.warning("æœªä¸Šä¼ æ–‡ä»¶")
                st.stop()
    elif selection == options[1]:
        img_url = st.text_input("è¯·è¾“å…¥å›¾ç‰‡URL")
        if st.button("æ£€æµ‹"):
            try:
                response = requests.get(img_url, stream=True)
                response.raise_for_status()

                # å°†å›¾ç‰‡æ•°æ®å†™å…¥æœ¬åœ°æ–‡ä»¶
                with open('predict_img.jpg', "wb") as file:
                    for chunk in response.iter_content(1024):
                        file.write(chunk)
                file.close()
                st.success("æˆåŠŸè¯»å–å›¾ç‰‡", icon='âœ…')
            except requests.exceptions.RequestException as e:
                st.error("è¯»å–å›¾ç‰‡å‡ºé”™", icon='ğŸš¨')
                st.stop()

            frame_rgb, count_num = predict_image()
            timestamp = int(time.time())
            cv2.imwrite("history/{}_image.jpg".format(timestamp), cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR))
            with open("history.txt", mode='a+', encoding='utf8') as f:
                f.write("{}\t{}\n".format('history/{}_image.jpg'.format(timestamp),
                                          datetime.now().strftime('%Y-%m-%d')))
            f.close()
            col1, col2 = st.columns([5, 5])
            with col1:
                st.image("predict_img.jpg")
            with col2:
                st.image(frame_rgb, channels="RGB")
                st.markdown("<h4 style='text-align: center'>æ£€æµ‹ä¸ªæ•°: {}</h4>".format(count_num), unsafe_allow_html=True)
            img_pil = Image.fromarray(frame_rgb)
            buf = BytesIO()
            img_pil.save(buf, format="JPEG")
            byte_im = buf.getvalue()

            st.download_button(
                label="Download result",
                data=byte_im,
                file_name="{}_image_url_predict.jpg".format(int(time.time())),
                mime="image/jpg"
            )

elif selected == 'è§†é¢‘æ£€æµ‹':
    options = [":material/movie:è¯»å–è§†é¢‘", ":material/link:è¯»å–URL"]
    selection = st.pills("è¯·é€‰æ‹©è¯»å–æ–¹å¼", options, default=":material/movie:è¯»å–è§†é¢‘")
    if selection == options[0]:
        uploaded_file = st.file_uploader("ä¸Šä¼ è§†é¢‘æ–‡ä»¶", type=["mp4", "mov"])
        start_btn = st.button("æ£€æµ‹")
        col1, col2 = st.columns([5, 5])
        if start_btn:
            if uploaded_file is not None:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                temp_file.write(uploaded_file.read())
                video_path = temp_file.name
                predict_video(video_path)
                with col1:
                    st.video(video_path, autoplay=True, muted=True)
                with col2:
                    st.video(open("predict_video.mp4", "rb").read(), autoplay=True, muted=True)
                timestamp = int(time.time())
                shutil.copy('./predict_video.mp4', 'history/{}_video.mp4'.format(timestamp))
                with open("history.txt", mode='a+', encoding='utf8') as f:
                    f.write("{}\t{}\n".format('history/{}_video.mp4'.format(timestamp),
                                              datetime.now().strftime('%Y-%m-%d')))
                f.close()
                with open("predict_video.mp4", "rb") as file:
                    btn = st.download_button(
                        label="Download result",
                        data=file,
                        file_name="{}_video_file_predict.mp4".format(int(time.time())),
                        mime="video/mp4",
                    )
            else:
                st.warning("æœªä¸Šä¼ æ–‡ä»¶")
                st.stop()
    elif selection == options[1]:
        video_url = st.text_input("è¯·è¾“å…¥è§†é¢‘URL")
        if st.button("æ£€æµ‹"):
            try:
                # ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                urllib.request.urlretrieve(video_url, temp_file.name)
                video_path = temp_file.name
                st.success("æˆåŠŸè¯»å–è§†é¢‘", icon='âœ…')
            except:
                st.error("è¯»å–è§†é¢‘å‡ºé”™", icon='ğŸš¨')
                st.stop()
            predict_video(video_path)
            col1, col2 = st.columns([5, 5])
            with col1:
                st.video(video_path, autoplay=True, muted=True)
            with col2:
                st.video(open("predict_video.mp4", "rb").read(), autoplay=True, muted=True)
            timestamp = int(time.time())
            shutil.copy('./predict_video.mp4', 'history/{}_video.mp4'.format(timestamp))
            with open("history.txt", mode='a+', encoding='utf8') as f:
                f.write("{}\t{}\n".format('history/{}_video.mp4'.format(timestamp),
                                          datetime.now().strftime('%Y-%m-%d')))
            f.close()
            with open("predict_video.mp4", "rb") as file:
                btn = st.download_button(
                    label="Download result",
                    data=file,
                    file_name="{}_video_url_predict.mp4".format(int(time.time())),
                    mime="video/mp4",
                )

elif selected == 'æ‘„åƒå¤´æ£€æµ‹':
    run = st.toggle("å¼€å¯æ‘„åƒå¤´")
    frame_placeholder = st.empty()

    # æ•è·æ‘„åƒå¤´å®æ—¶æµ
    cap = cv2.VideoCapture(0)  # 0ä»£è¡¨é»˜è®¤æ‘„åƒå¤´

    # è¿è¡Œå®æ—¶æ£€æµ‹å¾ªç¯
    while run:
        ret, frame = cap.read()
        if not ret:
            st.error("æ— æ³•è¯»å–æ‘„åƒå¤´è¾“å…¥", icon='ğŸš¨')
            break

        results = st.session_state[model_select].predict(source=frame, **{'save': False, 'show_conf': False},
                                                         stream=True)

        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        for result in results:
            label_dic = result.names
            for a, b, c in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.cls.cpu().numpy(), result.boxes.conf):
                # è·å–è¾¹ç•Œæ¡†åæ ‡å’Œæ ‡ç­¾
                x1, y1, x2, y2 = map(int, a)  # è¾¹ç•Œæ¡†åæ ‡
                label = label_dic[b]
                confidence = c

                # åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 5)
                text = f"{label} ({confidence:.2f})"
                font_scale = 1
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_thickness = 2

                text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]
                text_x, text_y = x1, y1 - 10
                text_bg_x1, text_bg_y1 = text_x, text_y - text_size[1]
                text_bg_x2, text_bg_y2 = text_x + text_size[0], text_y

                cv2.rectangle(frame, (text_bg_x1, text_bg_y1), (text_bg_x2, text_bg_y2), (0, 0, 255), -1)
                cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), font_thickness,
                            lineType=cv2.LINE_AA)
        # è½¬æ¢ä¸ºRGBæ ¼å¼
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        frame_placeholder.image(frame_rgb, channels="RGB")

        # æ§åˆ¶åˆ·æ–°é¢‘ç‡ï¼Œæ¯10msåˆ·æ–°ä¸€æ¬¡
        cv2.waitKey(10)

    # åœæ­¢æ‘„åƒå¤´
    cap.release()

elif selected == 'å†å²æ£€æµ‹':
    with open("history.txt", "r", encoding='utf8') as f:
        res = f.readlines()
    f.close()
    show_info = [_.split('\t') for _ in res]
    col1, col2, col3 = st.columns([3, 3, 3])
    with col1:
        options = [":material/image:å›¾ç‰‡æ£€æµ‹å†å²", ":material/movie:è§†é¢‘æ£€æµ‹å†å²"]
        selection = st.pills("è¯·é€‰æ‹©æµè§ˆçš„å†å²å†…å®¹ç±»åˆ«", options, default=":material/image:å›¾ç‰‡æ£€æµ‹å†å²")
    with col2:
        option_year = st.selectbox(
            "å¹´ä»½ç­›é€‰",
            tuple(set([_[1].split('-')[0] for _ in show_info])),
        )
    with col3:
        option_month = st.selectbox(
            "æœˆä»½ç­›é€‰",
            tuple(set([_[1].split('-')[1] for _ in show_info])),
        )
    if selection == ':material/image:å›¾ç‰‡æ£€æµ‹å†å²':
        col4, col5, col6, col7, col8 = st.columns([2, 2, 2, 2, 2])
        detail = [_ for _ in show_info if 'image' in _[0]]
        numbers = list(range(len(detail)))
        result = [[numbers[i] for i in range(j, len(detail), 5)] for j in range(5)]
        for inx, item in enumerate(detail):
            if inx in result[0]:
                with col4:
                    st.image(item[0])
                    st.markdown("<p style='text-align: center'>æ£€æµ‹æ—¶é—´: {}</p>".format(item[1]), unsafe_allow_html=True)
            elif inx in result[1]:
                with col5:
                    st.image(item[0])
                    st.markdown("<p style='text-align: center'>æ£€æµ‹æ—¶é—´: {}</p>".format(item[1]), unsafe_allow_html=True)
            elif inx in result[2]:
                with col6:
                    st.image(item[0])
                    st.markdown("<p style='text-align: center'>æ£€æµ‹æ—¶é—´: {}</p>".format(item[1]), unsafe_allow_html=True)
            elif inx in result[3]:
                with col7:
                    st.image(item[0])
                    st.markdown("<p style='text-align: center'>æ£€æµ‹æ—¶é—´: {}</p>".format(item[1]), unsafe_allow_html=True)
            elif inx in result[4]:
                with col8:
                    st.image(item[0])
                    st.markdown("<p style='text-align: center'>æ£€æµ‹æ—¶é—´: {}</p>".format(item[1]), unsafe_allow_html=True)
    elif selection == ':material/movie:è§†é¢‘æ£€æµ‹å†å²':
        col4, col5 = st.columns([5, 5])
        detail = [_ for _ in show_info if 'video' in _[0]]
        for inx, item in enumerate(detail):
            if inx % 2 == 0:
                with col4:
                    st.video(item[0])
                    st.markdown("<p style='text-align: center'>æ£€æµ‹æ—¶é—´: {}</p>".format(item[1]), unsafe_allow_html=True)
            else:
                with col5:
                    st.video(item[0])
                    st.markdown("<p style='text-align: center'>æ£€æµ‹æ—¶é—´: {}</p>".format(item[1]), unsafe_allow_html=True)

elif selected == 'è®¡æ•°å¯è§†åŒ–':
    st.subheader("è®¡æ•°å¯è§†åŒ–")
    # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå‡½æ•° get_detection_counts() è¿”å›æ£€æµ‹æ—¶é—´å’Œæ£€æµ‹ä¸ªæ•°
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦æ¨¡æ‹Ÿæˆ–ä»å®é™…æ£€æµ‹ä¸­è·å–è¿™äº›æ•°æ®
    detection_times = []  # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„æ£€æµ‹æ—¶é—´æ•°æ®
    detection_counts = []  # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„æ£€æµ‹ä¸ªæ•°æ•°æ®

    # ç»˜åˆ¶æŠ˜çº¿å›¾
    fig, ax = plt.subplots()
    ax.plot(detection_times, detection_counts, marker='o')
    ax.set_xlabel('æ£€æµ‹æ—¶é—´')
    ax.set_ylabel('æ£€æµ‹ä¸ªæ•°')
    ax.set_title('æ£€æµ‹ä¸ªæ•°éšæ—¶é—´å˜åŒ–å›¾')
    st.pyplot(fig)
